{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc561b7a-7938-4e08-8c40-22e3643c623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "363f586e-7381-4076-876a-7e8edfc8fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9043a29e-7e6a-4f1a-818b-7ee44e969c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model from scratch\n",
    "class WasteClassifierCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(WasteClassifierCNN, self).__init__()\n",
    "        # Define layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  # Input: 3x224x224 → Output: 16x224x224\n",
    "        self.pool = nn.MaxPool2d(2, 2)               # Output: 16x112x112\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1) # Output: 32x112x112 → pool → 32x56x56\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)      # Flatten and FC layer\n",
    "        self.fc2 = nn.Linear(128, num_classes)       # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Conv1 + ReLU + Pool\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Conv2 + ReLU + Pool\n",
    "        x = x.view(-1, 32 * 56 * 56)          # Flatten to 1D vector\n",
    "        x = F.relu(self.fc1(x))               # FC1 + ReLU\n",
    "        x = self.fc2(x)                       # Output layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa98b276-5b9c-4e64-b187-a68ca965c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations for training and testing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # Resize to 224x224 for the input images\n",
    "    transforms.ToTensor(),           # Convert images to tensor\n",
    "])\n",
    "\n",
    "# Load the dataset using ImageFolder\n",
    "train_dataset = datasets.ImageFolder('NDATA/DATASET/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Optionally, load the test dataset for evaluation\n",
    "test_dataset = datasets.ImageFolder('NDATA/DATASET/train', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb9c3fa9-616d-48f6-b89a-8716a8c61bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "num_classes = len(train_dataset.classes)  # Get number of classes from the dataset\n",
    "model = WasteClassifierCNN(num_classes).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b833ab01-8946-4af7-a444-ba592e142c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = datasets.ImageFolder('NDATA/DATASET/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define CNN Model\n",
    "class WasteClassifierCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(WasteClassifierCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 3x224x224 → 16x112x112\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 16x112x112 → 32x56x56\n",
    "        x = x.view(-1, 32 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate model\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = WasteClassifierCNN(num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b24e757b-82c6-4493-a7d4-241a87f39f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6302, Accuracy: 73.70%\n",
      "Epoch 2, Loss: 0.5323, Accuracy: 78.18%\n",
      "Epoch 3, Loss: 0.4501, Accuracy: 81.70%\n",
      "Epoch 4, Loss: 0.3521, Accuracy: 85.84%\n",
      "Epoch 5, Loss: 0.2445, Accuracy: 90.40%\n",
      "Epoch 6, Loss: 0.1577, Accuracy: 94.07%\n",
      "Epoch 7, Loss: 0.1034, Accuracy: 96.29%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(7):  # You can increase the number of epochs as needed\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Loop through batches of data\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize the weights\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Accumulate the loss for averaging\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    " \n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64654b7d-41e4-4560-b4d4-6b9910cf9f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.25%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation after training\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No need to compute gradients during evaluation\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate final accuracy on the test set\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb37d3c2-d771-44a7-90bf-52480725a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'waste_combined.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240486f6-fb5e-40bc-bcb7-439d8cee9275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
